# Indonesian-NLP-Resources
This is a repository for Indonesian NLP resources. The dataset belongs to the respective owners, we just listed here to facilitate the search. The dataset is downloadable as in the current date: April 18th, 2020.

## Parallel corpora
* [Asian Language Treebank (ALT)](http://www2.nict.go.jp/astrec-att/member/mutiyama/ALT/)
  * The dataset consist of around 20,000 sentences from English Wikinews and translated into nine languages, viz., Filipino, Indonesian, Japanese, Khmer, Laotian, Malay, Myanmar, Thai, Vietnamese. 
  * The dataset domain is news.
* [TUFS Asian Language Parallel Corpus (TALPCo)](https://github.com/matbahasa/TALPCo).
  * The dataset consist of XXX sentences. The TUFS Asian Language Parallel Corpus (TALPCo) is an open parallel corpus consisting of Japanese sentences and their translations into Burmese, Malay, Indonesian, Thai, Vietnamese and English.
  * The dataset domain is XXX
* [Open Parallel Corpus (OPUS)](http://opus.nlpl.eu/)
  * OPUS is a growing collection of translated texts from the web. 
  * The dataset domain is various such as JW300, translated movie subtitles (Open subtitles), localization files (GNOME, Ubuntu, KDE4), open multilingual collection of subtitles for educational videos and lectures (QCRI Educational Domain Corpus), a collection of Quran translations (Tanzil), Wikipedia translations (wikimedia), translated sentences from Tatoeba (Tatoeba).
* [List of Workshop on Machine Translation (WMT)](http://www.statmt.org/wmt19/translation-task.html)
  * [News Commentary v14](http://data.statmt.org/news-commentary/v14/training/)
   * This is WMT series dataset of shared tasks. It consists of both parallel and monolingual data sets. 
   * The languages included are Arabic, Chinese, Czech, Dutch, English, French, German, Hindi, Indonesian, Italian, Japanese,  Kazakh, Portugese, Russian and Spanish.
  
## Monolingual Corpora
* [Leipzig Corpora Collection](https://wortschatz.uni-leipzig.de/en/download/)
 * The Leipzig Corpora Collection presents corpora in different languages using the same format and comparable sources. 
 * The dataset domain consist of news, web, wikipedia, and mixed.
* [List of Workshop on Machine Translation (WMT)](http://www.statmt.org/wmt19/translation-task.html)
  * [News Commentary v14](http://data.statmt.org/news-commentary/v14/training-monolingual/)
   * This is WMT series dataset of shared tasks. It consists of both parallel and monolingual data sets. 
   * The languages included are Arabic, Chinese, Czech, Dutch, English, French, German, Hindi, Indonesian, Italian, Japanese,  Kazakh, Portugese, Russian and Spanish.
* [TED-Multilingual-Parallel-Corpus](https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus)

